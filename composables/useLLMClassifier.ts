import { useTransactionStore } from '~/stores/transaction'
import { parseGeminiResponse } from '~/utils/geminiParser'

export interface LLMClassifierResult {
  type: 'income' | 'expense';
  /** ä¸»é¡åˆ¥ï¼ˆèˆ‡ categoryIds[0] ä¸€è‡´ï¼Œä¿ç•™ç›¸å®¹æ€§ï¼‰ */
  categoryId: string;
  /** æœ€å¤š 3 å€‹é¡åˆ¥ï¼Œä¾å„ªå…ˆé †åºæ’åˆ—ï¼ˆä¸»â†’æ¬¡â†’è¼”ï¼‰ */
  categoryIds?: string[];
  confidence: number;
  /** å¯é¸ï¼šå„é¡åˆ¥å°æ‡‰çš„ç½®ä¿¡åº¦ï¼Œé †åºèˆ‡ categoryIds å°æ‡‰ */
  confidences?: number[];
  description: string;
  explanation: string;
  errorMessage?: string;
  metadata?: {
    processingTime?: number;
    apiAttempts?: number;
    fallbackUsed?: boolean;
    confidenceFactors?: string[];
  };
}

export interface ClassificationOptions {
  enableFallback?: boolean;
  maxRetries?: number;
  timeoutMs?: number;
  includeMetadata?: boolean;
}

/**
 * ğŸ¯ Focused LLM Transaction Classifier
 * 
 * Core Mission: Precise income/expense detection and accurate category classification
 * 
 * Key Features:
 * ğŸ” Smart Income/Expense Detection - Advanced keyword analysis for transaction type
 * ğŸ“‚ Precise Category Matching - Context-aware mapping to correct categories  
 * âš¡ Optimized Classification - Streamlined prompts for better accuracy
 * ğŸ›¡ï¸ Robust Error Handling - Fallback mechanisms and retry logic
 * 
 * @example
 * ```typescript
 * const { classifyWithLLM } = useLLMClassifier()
 * const result = await classifyWithLLM("æ˜Ÿå·´å…‹å’–å•¡ 120å…ƒ")
 * // Returns: { type: "expense", categoryId: "food", confidence: 95, ... }
 * ```
 */
export function useLLMClassifier() {
  const store = useTransactionStore()
  
  /**
   * Focused Classification Prompt - Optimized for Category Accuracy
   * Core Focus: Precise income/expense detection and category matching
   */
  const buildClassificationPrompt = (inputText: string): string => {
    const expenseCategories = store.categories
      .filter(c => c.type === 'expense')
      .map(c => `${c.id}: ${c.name}`)
      .join('\n')
    const incomeCategories = store.categories
      .filter(c => c.type === 'income')
      .map(c => `${c.id}: ${c.name}`)
      .join('\n')
    
    return `ä½ æ˜¯äº¤æ˜“åˆ†é¡å°ˆå®¶ï¼Œå°ˆç²¾æ–¼åˆ¤æ–·äº¤æ˜“æ˜¯ã€Œæ”¯å‡ºã€é‚„æ˜¯ã€Œæ”¶å…¥ã€ï¼Œä¸¦ç²¾æº–åŒ¹é…åˆ°æ­£ç¢ºé¡åˆ¥ï¼ˆæ”¯æ´æœ€å¤š 3 å€‹é¡åˆ¥ï¼Œä»¥ä¸»â†’æ¬¡â†’è¼”é †åºï¼‰ã€‚

## åˆ†é¡ä»»å‹™
è¼¸å…¥: "${inputText}"

## æ”¯å‡ºé¡åˆ¥æ¸…å–®
${expenseCategories}

## æ”¶å…¥é¡åˆ¥æ¸…å–®  
${incomeCategories}

## åˆ†é¡æ–¹æ³•
1. å…ˆåˆ¤æ–·æ˜¯æ”¯å‡ºé‚„æ˜¯æ”¶å…¥ï¼ˆä¸å¯æ··ç”¨ï¼‰
2. å¾å°æ‡‰é¡åˆ¥ä¸­é¸å‡ºæœ€åŒ¹é…çš„ 1~3 å€‹ IDï¼ˆä¸»â†’æ¬¡â†’è¼”ï¼Œæœ€å¤š 3 å€‹ï¼‰
3. è«‹ç¢ºä¿æ‰€æœ‰é¸æ“‡çš„é¡åˆ¥çš†å±¬æ–¼ç›¸åŒçš„ typeï¼ˆincome æˆ– expenseï¼‰
4. å›å‚³æ•´é«”ä¿¡å¿ƒåˆ†æ•¸ï¼Œä¸¦ï¼ˆå¯é¸ï¼‰å›å‚³å„é¡åˆ¥å°æ‡‰çš„ä¿¡å¿ƒåˆ†æ•¸é™£åˆ—

## é—œéµåˆ†é¡è¦å‰‡
**æ”¯å‡ºåˆ¤æ–·æ¨™æº–:**
- è³¼è²·ã€æ¶ˆè²»ã€èŠ±è²»ã€ä»˜æ¬¾ã€æ”¯ä»˜
- åº—å®¶åç¨±ã€å•†å“æœå‹™
- "è²·äº†"ã€"èŠ±äº†"ã€"ä»˜äº†"

**æ”¶å…¥åˆ¤æ–·æ¨™æº–:**  
- è–ªæ°´ã€çé‡‘ã€æ”¶åˆ°ã€å…¥å¸³ã€è³ºåˆ°
- å·¥ä½œã€å…¼è·ã€æŠ•è³‡ã€é€€æ¬¾
- "æ”¶å…¥"ã€"é ˜åˆ°"ã€"ç™¼æ”¾"

**é¡åˆ¥åŒ¹é…é‚è¼¯:**
- food: é¤å»³ã€å°åƒã€é£²æ–™ã€é£Ÿç‰©ã€ç”¨é¤
- transport: æ·é‹ã€å…¬è»Šã€è¨ˆç¨‹è»Šã€åŠ æ²¹ã€åœè»Š
- shopping: è³¼ç‰©ã€è¡£æœã€æ—¥ç”¨å“ã€ç¶²è³¼ã€ç™¾è²¨
- entertainment: é›»å½±ã€éŠæˆ²ã€KTVã€æ—…éŠã€å¨›æ¨‚ã€ç©å…·ã€å—œå¥½
- healthcare: é†«é™¢ã€è—¥å±€ã€çœ‹é†«ç”Ÿã€å¥æª¢ã€ä¿å¥
- education: å­¸è²»ã€èª²ç¨‹ã€è£œç¿’ã€æ›¸ç±ã€å­¸ç¿’
- utilities: æ°´é›»ã€ç“¦æ–¯ã€ç¶²è·¯ã€é›»è©±ã€æˆ¿ç§Ÿ
- salary: è–ªæ°´ã€æœˆè–ªã€å·¥è³‡ã€æœ¬è–ª
- bonus: çé‡‘ã€å¹´çµ‚ã€ç´…åˆ©ã€ææˆ
- investment: è‚¡ç¥¨ã€åŸºé‡‘ã€ç†è²¡ã€æŠ•è³‡æ”¶ç›Š

## è¼¸å‡ºæ ¼å¼
åªå›å‚³ç´”JSONï¼Œä¸è¦markdownæ ¼å¼åŒ…è£ï¼Œä¸è¦åŠ ä»»ä½•å…¶ä»–æ–‡å­—:
{
  "type": "expense" | "income",
  "categoryIds": ["ä¸»é¡åˆ¥ID", "æ¬¡é¡åˆ¥ID", "è¼”é¡åˆ¥ID"], // 1~3 å€‹ï¼Œä¸»é¡åˆ¥æ’ç¬¬ä¸€
  "categoryId": "ä¸»é¡åˆ¥ID", // èˆ‡ categoryIds[0] ç›¸åŒï¼Œæä¾›ç›¸å®¹æ€§
  "confidence": 0-100æ•´æ•¸, // æ•´é«”ä¿¡å¿ƒ
  "confidences": [95, 70, 55], // å¯é¸ï¼šèˆ‡ categoryIds é †åºå°æ‡‰
  "description": "ç°¡æ½”æè¿°ï¼Œæ ¼å¼: ä¸»é«” é‡‘é¡å…ƒ",
  "explanation": "åˆ†é¡ç†ç”±"
}

## åˆ†é¡ç¯„ä¾‹
"æ˜Ÿå·´å…‹å’–å•¡85å…ƒ" â†’ type: "expense", categoryIds: ["food"], categoryId: "food"
"åˆé¤éº¥ç•¶å‹å¤–é€+åŠ åƒ¹è³¼é£²æ–™" â†’ type: "expense", categoryIds: ["food", "shopping"], categoryId: "food"
"å…¬å¸ç™¼è–ª35000" â†’ type: "income", categoryIds: ["salary"], categoryId: "salary"
"è‚¡ç¥¨ç²åˆ©8000" â†’ type: "income", categoryIds: ["investment"], categoryId: "investment"`
  }

  /**
   * ğŸš€ Enhanced LLM Classification with Streaming Support
   * Features: Progressive loading, streaming responses, immediate feedback
   */
  const classifyWithLLM = async (
    description: string,
    options?: {
      enableStreaming?: boolean;
      onProgress?: (stage: string, progress: number) => void;
      onIntermediateResult?: (result: Partial<LLMClassifierResult>) => void;
    }
  ): Promise<LLMClassifierResult> => {
    const { enableStreaming = false, onProgress, onIntermediateResult } = options || {}

    if (!description || !description.trim()) {
      return createFallbackResult('', 'æœªæä¾›äº¤æ˜“æè¿°')
    }

    const fallbackResult = createFallbackResult(description)
    onIntermediateResult?.(fallbackResult)
    onProgress?.('æ­£åœ¨æº–å‚™åˆ†æ...', 10)

    const preprocessedInput = preprocessInput(description)
    onProgress?.('æ­£åœ¨è™•ç†è¼¸å…¥...', 20)

    const runtimeConfig = useRuntimeConfig()
    const apiKey = runtimeConfig.public.geminiApiKey
    if (!apiKey) {
      onProgress?.('ç¼ºå°‘ Gemini API Keyï¼Œä½¿ç”¨å‚™æ´åˆ†é¡', 100)
      const fallback = createFallbackResult(preprocessedInput, 'ç¼ºå°‘ Gemini API Key')
      fallback.metadata = { fallbackUsed: true }
      return fallback
    }

    try {
      const prompt = buildClassificationPrompt(preprocessedInput)
      onProgress?.('æ­£åœ¨é€£æ¥ AI æœå‹™...', 30)

      const startTime = Date.now()
      const generationConfig = { temperature: 0.1, maxOutputTokens: 1024 }
      const model = 'gemini-flash-latest'
      const resolvedApiKey = apiKey as string

      let result: LLMClassifierResult
      if (enableStreaming) {
        result = await handleStreamingClassification({
          prompt,
          model,
          apiKey: resolvedApiKey,
          input: preprocessedInput,
          generationConfig,
          onProgress,
          onIntermediateResult
        })
      } else {
        result = await handleStandardClassification({
          prompt,
          model,
          apiKey: resolvedApiKey,
          input: preprocessedInput,
          generationConfig,
          onProgress
        })
      }

      const processingTime = Date.now() - startTime
      result.metadata = {
        ...result.metadata,
        processingTime,
        fallbackUsed: false
      }

      onProgress?.('åˆ†æå®Œæˆ', 100)
      console.log(`âœ… Gemini Classification completed in ${processingTime}ms`)
      return result
    } catch (error: any) {
      console.error('âŒ Gemini classification failed:', error)
      console.error('âŒ Full error details:', {
        message: error.message,
        stack: error.stack,
        preprocessedInput
      })
      onProgress?.('åˆ†æå¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨åˆ†é¡', 100)

      const errorResult = createFallbackResult(preprocessedInput, `LLMåˆ†æå¤±æ•—: ${error?.message || 'æœªçŸ¥éŒ¯èª¤'}`)
      errorResult.metadata = { fallbackUsed: true, processingTime: Date.now() }
      return errorResult
    }
  }

  /**
   * ğŸŒŠ è™•ç†æµå¼åˆ†é¡éŸ¿æ‡‰
   */
  const handleStreamingClassification = async ({
    prompt,
    model,
    apiKey,
    input,
    generationConfig,
    onProgress,
    onIntermediateResult
  }: {
    prompt: string
    model: string
    apiKey: string
    input: string
    generationConfig: { temperature: number; maxOutputTokens: number }
    onProgress?: (stage: string, progress: number) => void
    onIntermediateResult?: (result: Partial<LLMClassifierResult>) => void
  }): Promise<LLMClassifierResult> => {
    onProgress?.('é–‹å§‹æµå¼åˆ†æ...', 40)

    const response = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/models/${model}:streamGenerateContent?key=${apiKey}`,
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Accept': 'text/event-stream'
        },
        body: JSON.stringify({
          systemInstruction: {
            role: 'system',
            parts: [{ text: 'ä½ æ˜¯å¿«é€Ÿäº¤æ˜“åˆ†é¡AIã€‚è«‹åˆ†æä¸¦å›å‚³ç´”JSONæ ¼å¼ï¼Œä¸è¦ç”¨markdownåŒ…è£ï¼Œä¸è¦åŠ ä»»ä½•é¡å¤–æ–‡å­—ã€‚' }]
          },
          contents: [
            {
              role: 'user',
              parts: [{ text: prompt }]
            }
          ],
          generationConfig
        })
      }
    )

    if (!response.ok) {
      throw new Error(`APIè«‹æ±‚å¤±æ•—: ${response.status}`)
    }

    const reader = response.body?.getReader()
    if (!reader) {
      throw new Error('ç„¡æ³•å»ºç«‹ä¸²æµè®€å–å™¨')
    }

    const decoder = new TextDecoder()
    let accumulatedContent = ''
    let progress = 50

    try {
      while (true) {
        const { done, value } = await reader.read()
        if (done) break

        const chunk = decoder.decode(value, { stream: true })
        const lines = chunk.split('\n')

        for (const rawLine of lines) {
          const line = rawLine.trim()
          if (!line.startsWith('data:')) continue

          const data = line.slice(5).trim()
          if (!data || data === '[DONE]') {
            progress = Math.min(progress + 5, 90)
            onProgress?.('æ­£åœ¨å®Œæˆåˆ†æ...', progress)
            continue
          }

          try {
            const parsed = JSON.parse(data)
            const parts = parsed.candidates?.[0]?.content?.parts || []
            const textChunk = parts.map((part: any) => part?.text || '').join('')

            if (textChunk) {
              accumulatedContent += textChunk
              progress = Math.min(progress + 5, 85)
              onProgress?.('æ­£åœ¨æ¥æ”¶åˆ†æçµæœ...', progress)

              const partialResult = tryParsePartialResult(accumulatedContent)
              if (partialResult) {
                onIntermediateResult?.(partialResult)
              }
            }
          } catch {
            // å¿½ç•¥ JSON è§£æéŒ¯èª¤ï¼Œç¹¼çºŒè™•ç†
          }
        }
      }

      onProgress?.('æ­£åœ¨é©—è­‰çµæœ...', 95)
      
      // ä½¿ç”¨æ–°çš„è§£æå·¥å…·è™•ç†æœ€çµ‚çµæœ
      try {
        const mockResponse = {
          candidates: [{ content: { parts: [{ text: accumulatedContent }] } }]
        }
        const finalResult = parseGeminiResponse<any>(mockResponse)
        return parseAndValidateResult(finalResult, input)
      } catch (parseError) {
        console.error('âŒ Final stream parse failed, using raw content:', parseError)
        return parseAndValidateResult(accumulatedContent, input)
      }
    } finally {
      reader.releaseLock()
    }
  }

  /**
   * ğŸ“‹ è™•ç†æ¨™æº–åˆ†é¡éŸ¿æ‡‰ï¼ˆå„ªåŒ–ç‰ˆï¼‰
   */
  const handleStandardClassification = async ({
    prompt,
    model,
    apiKey,
    input,
    generationConfig,
    onProgress
  }: {
    prompt: string
    model: string
    apiKey: string
    input: string
    generationConfig: { temperature: number; maxOutputTokens: number }
    onProgress?: (stage: string, progress: number) => void
  }): Promise<LLMClassifierResult> => {
    const timeoutPromise = new Promise<never>((_, reject) =>
      setTimeout(() => reject(new Error('è«‹æ±‚è¶…æ™‚')), 8000)
    )

    const requestPromise = fetch(
      `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${apiKey}`,
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          systemInstruction: {
            role: 'system',
            parts: [{ text: 'ä½ æ˜¯å¿«é€Ÿäº¤æ˜“åˆ†é¡AIã€‚è«‹åˆ†æä¸¦å›å‚³ç´”JSONæ ¼å¼ï¼Œä¸è¦ç”¨markdownåŒ…è£ï¼Œä¸è¦åŠ ä»»ä½•é¡å¤–æ–‡å­—ã€‚' }]
          },
          contents: [
            {
              role: 'user',
              parts: [{ text: prompt }]
            }
          ],
          generationConfig
        })
      }
    )

    onProgress?.('æ­£åœ¨ç­‰å¾…AIéŸ¿æ‡‰...', 50)

    const response = await Promise.race([requestPromise, timeoutPromise])

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}))
      throw new Error(`APIè«‹æ±‚å¤±æ•—: ${response.status} - ${errorData.error?.message || response.statusText}`)
    }

    onProgress?.('æ­£åœ¨è™•ç†éŸ¿æ‡‰...', 80)
    const data = await response.json()

    // ä½¿ç”¨æ–°çš„è§£æå·¥å…·ç›´æ¥è§£æ
    const parsedResult = parseGeminiResponse<any>(data)
    console.log('âœ… Parsed Gemini response:', parsedResult)
    
    // ç›´æ¥é©—è­‰è§£æå¾Œçš„ç‰©ä»¶ï¼Œä¸å†é€²è¡Œé¡å¤–çš„JSONå­—ç¬¦ä¸²åŒ–
    return parseAndValidateResult(parsedResult, input)
  }

  /**
   * ğŸ” å˜—è©¦è§£æéƒ¨åˆ†çµæœï¼ˆç”¨æ–¼æµå¼éŸ¿æ‡‰ï¼‰
   */
  const tryParsePartialResult = (content: string): Partial<LLMClassifierResult> | null => {
    try {
      // ä½¿ç”¨æ–°çš„è§£æå·¥å…·ï¼Œä½†å…è¨±éƒ¨åˆ†å¤±è´¥
      const mockResponse = {
        candidates: [{ content: { parts: [{ text: content }] } }]
      }
      
      let parsed: any
      try {
        parsed = parseGeminiResponse<any>(mockResponse)
      } catch {
        // å¦‚æœæ–°è§£æå™¨å¤±æ•—ï¼Œé€€å›åˆ°ç°¡å–®è§£æ
        const jsonMatch = content.match(/\{[\s\S]*\}/)
        if (!jsonMatch) return null
        parsed = JSON.parse(jsonMatch[0].trim())
      }
      
      // åªè¿”å›å·²ç¢ºå®šçš„éƒ¨åˆ†
      const partial: Partial<LLMClassifierResult> = {};
      
      if (parsed.type && ['expense', 'income'].includes(parsed.type)) {
        partial.type = parsed.type;
      }
      if (Array.isArray(parsed.categoryIds)) {
        const ids = parsed.categoryIds.filter((x: any) => typeof x === 'string')
        if (ids.length) {
          partial.categoryIds = ids.slice(0, 3)
          partial.categoryId = ids[0]
        }
      } else if (parsed.categoryId && typeof parsed.categoryId === 'string') {
        partial.categoryId = parsed.categoryId;
        partial.categoryIds = [parsed.categoryId]
      }
      
      if (typeof parsed.confidence === 'number') {
        partial.confidence = Math.round(parsed.confidence);
      }
      
      return Object.keys(partial).length > 0 ? partial : null;
    } catch {
      return null;
    }
  };
  
  /**
   * Input preprocessing for better classification
   */
  const preprocessInput = (input: string): string => {
    return input
      .trim()
      .replace(/\s+/g, ' ') // Normalize whitespace
      .replace(/[^\u4e00-\u9fa5a-zA-Z0-9\s\-$ï¿¥Â¥.,]/g, '') // Remove special chars except currency
      .substring(0, 200); // Limit length
  };
  
  /**
   * Enhanced JSON parsing with comprehensive validation
   */
  const parseAndValidateResult = (parsed: any, originalInput: string): LLMClassifierResult => {
    try {
      console.log('ğŸ” Validating parsed content:', parsed)
      
      // å¦‚æœè¼¸å…¥æ˜¯å­—ç¬¦ä¸²ï¼Œå‰‡è§£æå®ƒï¼›å¦å‰‡ç›´æ¥ä½¿ç”¨ç‰©ä»¶
      const content = typeof parsed === 'string' ? JSON.parse(parsed) : parsed
      
      // Comprehensive validation
      const validationErrors: string[] = [];
      
      if (!content.type || !['expense', 'income'].includes(content.type)) {
        validationErrors.push('äº¤æ˜“é¡å‹ç„¡æ•ˆ');
      }
      
      const validCategories = store.categories.filter(c => c.type === content.type);
      const validIds = new Set(validCategories.map(c => c.id))

      let categoryIds: string[] = []
      if (Array.isArray(content.categoryIds)) {
        categoryIds = content.categoryIds.filter((id: any) => typeof id === 'string' && validIds.has(id))
      }

      // å¾Œç›¸å®¹ï¼šè‹¥åªå›å‚³ categoryIdï¼Œä»ç„¶æ¥å—
      if ((!categoryIds || categoryIds.length === 0) && typeof content.categoryId === 'string' && validIds.has(content.categoryId)) {
        categoryIds = [content.categoryId]
      }
      if (!categoryIds || categoryIds.length === 0) {
        validationErrors.push('é¡åˆ¥IDç„¡æ•ˆ');
      }
      
      if (typeof content.confidence !== 'number' || content.confidence < 0 || content.confidence > 100) {
        validationErrors.push('ä¿¡å¿ƒåº¦æ•¸å€¼ç„¡æ•ˆ');
      }
      
      if (!content.description || typeof content.description !== 'string') {
        validationErrors.push('æè¿°æ ¼å¼ç„¡æ•ˆ');
      }
      
      if (validationErrors.length > 0) {
        throw new Error(`æ•¸æ“šé©—è­‰å¤±æ•—: ${validationErrors.join(', ')}`);
      }
      
      // Return validated result
      const result: LLMClassifierResult = {
        type: content.type,
        categoryId: categoryIds[0],
        categoryIds,
        confidence: Math.round(content.confidence),
        description: String(content.description || originalInput).trim(),
        explanation: content.explanation || 'ç”±AIæ™ºèƒ½åˆ†æå®Œæˆ'
      }
      if (Array.isArray(content.confidences)) {
        const cs = content.confidences.filter((n: any) => typeof n === 'number').map((n: number) => Math.round(n))
        if (cs.length) result.confidences = cs.slice(0, result.categoryIds?.length || 3)
      }
      return result;
      
    } catch (error: any) {
      console.error('JSONè§£æå¤±æ•—:', error.message, 'Content:', parsed);
      throw new Error(`çµæœè§£æå¤±æ•—: ${error.message}`);
    }
  };
  
  /**
   * Determine if an error is retryable
   */
  const isRetryableError = (error: any): boolean => {
    const retryableErrors = [
      'fetch', 'network', 'timeout', '429', '500', '502', '503', '504'
    ];
    
    const errorMessage = error?.message?.toLowerCase() || '';
    return retryableErrors.some(keyword => errorMessage.includes(keyword));
  };
  
  /**
   * Smart fallback classification with keyword-based category detection
   */
  const createFallbackResult = (description: string, errorContext?: string): LLMClassifierResult => {
    const lowerDesc = description.toLowerCase();
    
    // Smart category detection based on keywords
    let bestMatch = { category: store.categories.find(c => c.type === 'expense'), confidence: 25 };
    
    // Income keywords
    const incomeKeywords = ['è–ª', 'è–ªæ°´', 'è–ªè³‡', 'æ”¶å…¥', 'å…¥å¸³', 'çé‡‘', 'ç´…åˆ©', 'è‚¡æ¯', 'æŠ•è³‡', 'æ”¶åˆ°'];
    if (incomeKeywords.some(keyword => lowerDesc.includes(keyword))) {
      bestMatch = {
        category: store.categories.find(c => c.type === 'income') || 
                 store.categories.find(c => c.id === 'salary'),
        confidence: 60
      };
    }
    
    // Expense category keywords
    const categoryKeywords = {
      food: ['åƒ', 'å–', 'é¤', 'é£Ÿ', 'å’–å•¡', 'èŒ¶', 'éº¥ç•¶å‹', 'æ˜Ÿå·´å…‹', 'ä¾¿ç•¶', 'å°åƒ'],
      transport: ['äº¤é€š', 'è»Š', 'å…¬è»Š', 'æ·é‹', 'è¨ˆç¨‹è»Š', 'æ²¹', 'åœè»Š', 'uber'],
      shopping: ['è²·', 'è³¼', 'è¡£', 'é‹', 'åŒ…', 'åŒ–å¦', 'ç¶²è³¼', 'è¦çš®', 'æ·˜å¯¶'],
      entertainment: ['é›»å½±', 'éŠæˆ²', 'ktv', 'æ—…éŠ', 'å¨›æ¨‚', 'éŸ³æ¨‚', 'æ›¸'],
      healthcare: ['é†«', 'è—¥', 'å¥åº·', 'çœ‹ç—…', 'ç‰™é†«', 'çœ¼ç§‘', 'è¨ºæ‰€'],
      utilities: ['æ°´', 'é›»', 'ç“¦æ–¯', 'ç¶²è·¯', 'é›»è©±', 'æˆ¿ç§Ÿ', 'ç§Ÿé‡‘']
    };
    
    // Find best matching expense category
    for (const [categoryId, keywords] of Object.entries(categoryKeywords)) {
      if (keywords.some(keyword => lowerDesc.includes(keyword))) {
        const category = store.categories.find(c => c.id === categoryId);
        if (category) {
          bestMatch = { category, confidence: 70 };
          break;
        }
      }
    }
    
    // Final fallback
    const finalCategory = bestMatch.category || 
                         store.categories.find(c => c.type === 'expense') || 
                         store.categories[0] || 
                         { id: 'other', type: 'expense', name: 'å…¶ä»–' };
    
  return {
      type: finalCategory.type as 'expense' | 'income',
      categoryId: finalCategory.id,
      categoryIds: [finalCategory.id],
      confidence: bestMatch.confidence,
      description: description || 'æœªçŸ¥äº¤æ˜“',
      explanation: `AIåˆ†æå¤±æ•—ï¼Œä½¿ç”¨é—œéµå­—åŒ¹é…: ${errorContext || 'è‡ªå‹•åˆ†é¡'}`,
      errorMessage: errorContext
    };
  };
  
  return {
    // ğŸš€ ä¸»è¦åˆ†é¡æ–¹æ³•
    classifyWithLLM,
    
    // âš¡ å¿«é€Ÿåˆ†é¡ï¼ˆç„¡æµå¼éŸ¿æ‡‰ï¼Œæœ€å¿«é€Ÿåº¦ï¼‰
    classifyFast: async (description: string): Promise<LLMClassifierResult> => {
      return classifyWithLLM(description, { enableStreaming: false });
    },
    
    // ğŸŒŠ æµå¼åˆ†é¡ï¼ˆæ›´å¥½çš„ç”¨æˆ¶é«”é©—ï¼‰
    classifyStreaming: async (
      description: string, 
      callbacks: {
        onProgress: (stage: string, progress: number) => void;
        onIntermediateResult: (result: Partial<LLMClassifierResult>) => void;
      }
    ): Promise<LLMClassifierResult> => {
      return classifyWithLLM(description, {
        enableStreaming: true,
        onProgress: callbacks.onProgress,
        onIntermediateResult: callbacks.onIntermediateResult
      });
    },
    
    // ğŸ¯ æ™ºèƒ½åˆ†é¡ï¼ˆè‡ªå‹•é¸æ“‡æœ€ä½³æ–¹æ³•ï¼‰
    classifyIntelligent: async (
      description: string,
      options?: {
        preferSpeed?: boolean; // å„ªå…ˆé€Ÿåº¦é‚„æ˜¯é«”é©—
        onProgress?: (stage: string, progress: number) => void;
        onIntermediateResult?: (result: Partial<LLMClassifierResult>) => void;
      }
    ): Promise<LLMClassifierResult> => {
      const { preferSpeed = false } = options || {};
      
      // çŸ­æè¿°ä½¿ç”¨å¿«é€Ÿæ¨¡å¼ï¼Œé•·æè¿°ä½¿ç”¨æµå¼æ¨¡å¼
      const useStreaming = !preferSpeed && description.length > 20;
      
      return classifyWithLLM(description, {
        enableStreaming: useStreaming,
        onProgress: options?.onProgress,
        onIntermediateResult: options?.onIntermediateResult
      });
    },
    
    // Export for testing purposes
    buildClassificationPrompt,
    
    // æ‰¹é‡åˆ†é¡ï¼ˆé€²éšåŠŸèƒ½ï¼‰
    classifyBatch: async (descriptions: string[], options?: ClassificationOptions): Promise<LLMClassifierResult[]> => {
      const results: LLMClassifierResult[] = [];
      const startTime = Date.now();
      
      // ä¸¦è¡Œè™•ç†å°æ‰¹é‡ï¼Œé¿å… API é™åˆ¶
      const batchSize = 3;
      for (let i = 0; i < descriptions.length; i += batchSize) {
        const batch = descriptions.slice(i, i + batchSize);
        
        const batchPromises = batch.map(desc => 
          classifyWithLLM(desc, { enableStreaming: false })
        );
        
        const batchResults = await Promise.all(batchPromises);
        results.push(...batchResults);
        
        // æ‰¹æ¬¡é–“å»¶é²
        if (i + batchSize < descriptions.length) {
          await new Promise(resolve => setTimeout(resolve, 500));
        }
      }
      
      console.log(`âœ… Batch classification completed: ${descriptions.length} items in ${Date.now() - startTime}ms`);
      return results;
    },
    
    // ä¸¦è¡Œåˆ†é¡ï¼ˆæœ€å¿«ä½†æ¶ˆè€—æ›´å¤š API é…é¡ï¼‰
    classifyParallel: async (descriptions: string[], maxConcurrent = 5): Promise<LLMClassifierResult[]> => {
      const results: LLMClassifierResult[] = [];
      
      for (let i = 0; i < descriptions.length; i += maxConcurrent) {
        const batch = descriptions.slice(i, i + maxConcurrent);
        const batchPromises = batch.map(desc => classifyWithLLM(desc));
        const batchResults = await Promise.all(batchPromises);
        results.push(...batchResults);
      }
      
      return results;
    },
    
    // ç²å–åˆ†é¡çµ±è¨ˆ
    getClassificationStats: () => {
      const categories = store.categories;
      return {
        totalCategories: categories.length,
        expenseCategories: categories.filter(c => c.type === 'expense').length,
        incomeCategories: categories.filter(c => c.type === 'income').length,
        availableCategories: categories.map(c => ({ id: c.id, name: c.name, type: c.type }))
      };
    },
    
    // é©—è­‰è¼¸å…¥
    validateInput: (input: string): { isValid: boolean; issues: string[] } => {
      const issues: string[] = [];
      
      if (!input || !input.trim()) {
        issues.push('è¼¸å…¥ç‚ºç©º');
      }
      
      if (input.length > 200) {
        issues.push('è¼¸å…¥éé•·ï¼ˆè¶…é200å­—ç¬¦ï¼‰');
      }
      
      if (!/[\u4e00-\u9fa5]/.test(input) && !/[a-zA-Z]/.test(input)) {
        issues.push('ç¼ºå°‘æœ‰æ•ˆçš„æ–‡å­—å…§å®¹');
      }
      
      return {
        isValid: issues.length === 0,
        issues
      };
    },
    
    // ğŸ”§ å·¥å…·æ–¹æ³•
    utils: {
      preprocessInput,
      createFallbackResult,
      tryParsePartialResult
    }
  };
}