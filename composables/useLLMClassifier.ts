import { useTransactionStore } from '~/stores/transaction'

export interface LLMClassifierResult {
  type: 'income' | 'expense';
  categoryId: string;
  confidence: number;
  description: string;
  explanation: string;
  errorMessage?: string;
  metadata?: {
    processingTime?: number;
    apiAttempts?: number;
    fallbackUsed?: boolean;
    confidenceFactors?: string[];
  };
}

export interface ClassificationOptions {
  enableFallback?: boolean;
  maxRetries?: number;
  timeoutMs?: number;
  includeMetadata?: boolean;
}

/**
 * ğŸ¯ Focused LLM Transaction Classifier
 * 
 * Core Mission: Precise income/expense detection and accurate category classification
 * 
 * Key Features:
 * ğŸ” Smart Income/Expense Detection - Advanced keyword analysis for transaction type
 * ğŸ“‚ Precise Category Matching - Context-aware mapping to correct categories  
 * âš¡ Optimized Classification - Streamlined prompts for better accuracy
 * ğŸ›¡ï¸ Robust Error Handling - Fallback mechanisms and retry logic
 * 
 * @example
 * ```typescript
 * const { classifyWithLLM } = useLLMClassifier()
 * const result = await classifyWithLLM("æ˜Ÿå·´å…‹å’–å•¡ 120å…ƒ")
 * // Returns: { type: "expense", categoryId: "food", confidence: 95, ... }
 * ```
 */
export function useLLMClassifier() {
  const store = useTransactionStore()
  
  /**
   * Focused Classification Prompt - Optimized for Category Accuracy
   * Core Focus: Precise income/expense detection and category matching
   */
  const buildClassificationPrompt = (inputText: string): string => {
    const expenseCategories = store.categories
      .filter(c => c.type === 'expense')
      .map(c => `${c.id}: ${c.name}`)
      .join('\n')
    const incomeCategories = store.categories
      .filter(c => c.type === 'income')
      .map(c => `${c.id}: ${c.name}`)
      .join('\n')
    
    return `ä½ æ˜¯äº¤æ˜“åˆ†é¡å°ˆå®¶ï¼Œå°ˆç²¾æ–¼åˆ¤æ–·äº¤æ˜“æ˜¯ã€Œæ”¯å‡ºã€é‚„æ˜¯ã€Œæ”¶å…¥ã€ï¼Œä¸¦ç²¾ç¢ºåŒ¹é…åˆ°æ­£ç¢ºé¡åˆ¥ã€‚

## åˆ†é¡ä»»å‹™
è¼¸å…¥: "${inputText}"

## æ”¯å‡ºé¡åˆ¥æ¸…å–®
${expenseCategories}

## æ”¶å…¥é¡åˆ¥æ¸…å–®  
${incomeCategories}

## åˆ†é¡æ–¹æ³•
1. å…ˆåˆ¤æ–·æ˜¯æ”¯å‡ºé‚„æ˜¯æ”¶å…¥
2. å†å¾å°æ‡‰é¡åˆ¥ä¸­é¸æ“‡æœ€åŒ¹é…çš„ID
3. è©•ä¼°åˆ†é¡ç¢ºä¿¡åº¦

## é—œéµåˆ†é¡è¦å‰‡
**æ”¯å‡ºåˆ¤æ–·æ¨™æº–:**
- è³¼è²·ã€æ¶ˆè²»ã€èŠ±è²»ã€ä»˜æ¬¾ã€æ”¯ä»˜
- åº—å®¶åç¨±ã€å•†å“æœå‹™
- "è²·äº†"ã€"èŠ±äº†"ã€"ä»˜äº†"

**æ”¶å…¥åˆ¤æ–·æ¨™æº–:**  
- è–ªæ°´ã€çé‡‘ã€æ”¶åˆ°ã€å…¥å¸³ã€è³ºåˆ°
- å·¥ä½œã€å…¼è·ã€æŠ•è³‡ã€é€€æ¬¾
- "æ”¶å…¥"ã€"é ˜åˆ°"ã€"ç™¼æ”¾"

**é¡åˆ¥åŒ¹é…é‚è¼¯:**
- food: é¤å»³ã€å°åƒã€é£²æ–™ã€é£Ÿç‰©ã€ç”¨é¤
- transport: æ·é‹ã€å…¬è»Šã€è¨ˆç¨‹è»Šã€åŠ æ²¹ã€åœè»Š
- shopping: è³¼ç‰©ã€è¡£æœã€æ—¥ç”¨å“ã€ç¶²è³¼ã€ç™¾è²¨
- entertainment: é›»å½±ã€éŠæˆ²ã€KTVã€æ—…éŠã€å¨›æ¨‚ã€ç©å…·ã€å—œå¥½
- healthcare: é†«é™¢ã€è—¥å±€ã€çœ‹é†«ç”Ÿã€å¥æª¢ã€ä¿å¥
- education: å­¸è²»ã€èª²ç¨‹ã€è£œç¿’ã€æ›¸ç±ã€å­¸ç¿’
- utilities: æ°´é›»ã€ç“¦æ–¯ã€ç¶²è·¯ã€é›»è©±ã€æˆ¿ç§Ÿ
- salary: è–ªæ°´ã€æœˆè–ªã€å·¥è³‡ã€æœ¬è–ª
- bonus: çé‡‘ã€å¹´çµ‚ã€ç´…åˆ©ã€ææˆ
- investment: è‚¡ç¥¨ã€åŸºé‡‘ã€ç†è²¡ã€æŠ•è³‡æ”¶ç›Š

## è¼¸å‡ºæ ¼å¼
åªå›å‚³JSONï¼Œç„¡å…¶ä»–æ–‡å­—:
{
  "type": "expense" æˆ– "income",
  "categoryId": "å¿…é ˆæ˜¯ä¸Šè¿°IDä¹‹ä¸€", 
  "confidence": 0-100æ•´æ•¸,
  "description": "ç°¡æ½”æè¿°ï¼Œæ ¼å¼: ä¸»é«” é‡‘é¡å…ƒ",
  "explanation": "åˆ†é¡ç†ç”±"
}

## åˆ†é¡ç¯„ä¾‹
"æ˜Ÿå·´å…‹å’–å•¡85å…ƒ" â†’ type: "expense", categoryId: "food"
"å…¬å¸ç™¼è–ª35000" â†’ type: "income", categoryId: "salary"  
"æ·é‹å¡å„²å€¼500" â†’ type: "expense", categoryId: "transport"
"è‚¡ç¥¨ç²åˆ©8000" â†’ type: "income", categoryId: "investment"`
  }

  /**
   * ğŸš€ Enhanced LLM Classification with Streaming Support
   * Features: Progressive loading, streaming responses, immediate feedback
   */
  const classifyWithLLM = async (
    description: string, 
    options?: {
      enableStreaming?: boolean;
      onProgress?: (stage: string, progress: number) => void;
      onIntermediateResult?: (result: Partial<LLMClassifierResult>) => void;
    }
  ): Promise<LLMClassifierResult> => {
    const { enableStreaming = false, onProgress, onIntermediateResult } = options || {};
    
    if (!description || !description.trim()) {
      return createFallbackResult('', 'æœªæä¾›äº¤æ˜“æè¿°');
    }
    
    // ç«‹å³æä¾›æœ¬åœ°é åˆ†é¡çµæœ
    const fallbackResult = createFallbackResult(description);
    onIntermediateResult?.(fallbackResult);
    onProgress?.('æ­£åœ¨æº–å‚™åˆ†æ...', 10);
    
    // Input preprocessing
    const preprocessedInput = preprocessInput(description);
    onProgress?.('æ­£åœ¨è™•ç†è¼¸å…¥...', 20);
    
    try {
      const prompt = buildClassificationPrompt(preprocessedInput);
      const config = useRuntimeConfig();
      onProgress?.('æ­£åœ¨é€£æ¥AIæœå‹™...', 30);
      
      // å„ªåŒ–çš„ API é…ç½®ï¼Œæ”¯æŒæµå¼éŸ¿æ‡‰
      const apiConfig = {
        model: "gpt-3.5-turbo-1106", // ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹
        messages: [
          { 
            role: "system", 
            content: "ä½ æ˜¯å¿«é€Ÿäº¤æ˜“åˆ†é¡AIã€‚è«‹å¿«é€Ÿåˆ†æä¸¦ä»¥JSONæ ¼å¼å›å‚³åˆ†é¡çµæœã€‚" 
          },
          { role: "user", content: prompt }
        ],
        temperature: 0.1,
        max_tokens: 150, // é€²ä¸€æ­¥æ¸›å°‘ token æ•¸é‡
        ...(enableStreaming && { stream: true }) // æ”¯æŒæµå¼éŸ¿æ‡‰
      };
      
      const startTime = Date.now();
      let result: LLMClassifierResult;
      
      if (enableStreaming) {
        result = await handleStreamingClassification(apiConfig, preprocessedInput, onProgress, onIntermediateResult);
      } else {
        result = await handleStandardClassification(apiConfig, preprocessedInput, onProgress);
      }
      
      // è¨˜éŒ„æ€§èƒ½æŒ‡æ¨™
      const processingTime = Date.now() - startTime;
      result.metadata = {
        ...result.metadata,
        processingTime,
        fallbackUsed: false
      };
      
      onProgress?.('åˆ†æå®Œæˆ', 100);
      console.log(`âœ… LLM Classification completed in ${processingTime}ms`);
      
      return result;
      
    } catch (error: any) {
      console.error('âŒ LLM Classification failed:', error);
      onProgress?.('åˆ†æå¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨åˆ†é¡', 100);
      
      const errorResult = createFallbackResult(preprocessedInput, `LLMåˆ†æå¤±æ•—: ${error?.message || 'æœªçŸ¥éŒ¯èª¤'}`);
      errorResult.metadata = { fallbackUsed: true, processingTime: Date.now() };
      
      return errorResult;
    }
  };

  /**
   * ğŸŒŠ è™•ç†æµå¼åˆ†é¡éŸ¿æ‡‰
   */
  const handleStreamingClassification = async (
    apiConfig: any,
    input: string,
    onProgress?: (stage: string, progress: number) => void,
    onIntermediateResult?: (result: Partial<LLMClassifierResult>) => void
  ): Promise<LLMClassifierResult> => {
    const config = useRuntimeConfig();
    
    onProgress?.('é–‹å§‹æµå¼åˆ†æ...', 40);
    
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${config.public.openaiApiKey}`,
        'Accept': 'text/event-stream'
      },
      body: JSON.stringify(apiConfig)
    });
    
    if (!response.ok) {
      throw new Error(`APIè«‹æ±‚å¤±æ•—: ${response.status}`);
    }
    
    const reader = response.body?.getReader();
    if (!reader) {
      throw new Error('ç„¡æ³•å»ºç«‹ä¸²æµè®€å–å™¨');
    }
    
    const decoder = new TextDecoder();
    let accumulatedContent = '';
    let progress = 50;
    
    try {
      while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        
        const chunk = decoder.decode(value);
        const lines = chunk.split('\n');
        
        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const data = line.slice(6).trim();
            
            if (data === '[DONE]') {
              progress = 90;
              onProgress?.('æ­£åœ¨å®Œæˆåˆ†æ...', progress);
              break;
            }
            
            try {
              const parsed = JSON.parse(data);
              const content = parsed.choices?.[0]?.delta?.content;
              
              if (content) {
                accumulatedContent += content;
                progress = Math.min(progress + 5, 85);
                onProgress?.('æ­£åœ¨æ¥æ”¶åˆ†æçµæœ...', progress);
                
                // å˜—è©¦è§£æéƒ¨åˆ†çµæœ
                const partialResult = tryParsePartialResult(accumulatedContent);
                if (partialResult) {
                  onIntermediateResult?.(partialResult);
                }
              }
            } catch (e) {
              // å¿½ç•¥è§£æéŒ¯èª¤ï¼Œç¹¼çºŒè™•ç†
            }
          }
        }
      }
      
      onProgress?.('æ­£åœ¨é©—è­‰çµæœ...', 95);
      return parseAndValidateResult(accumulatedContent, input);
      
    } finally {
      reader.releaseLock();
    }
  };

  /**
   * ğŸ“‹ è™•ç†æ¨™æº–åˆ†é¡éŸ¿æ‡‰ï¼ˆå„ªåŒ–ç‰ˆï¼‰
   */
  const handleStandardClassification = async (
    apiConfig: any,
    input: string,
    onProgress?: (stage: string, progress: number) => void
  ): Promise<LLMClassifierResult> => {
    const config = useRuntimeConfig();
    
    // ä½¿ç”¨ä¸¦è¡Œè«‹æ±‚å’Œè¶…æ™‚æ§åˆ¶
    const timeoutPromise = new Promise<never>((_, reject) =>
      setTimeout(() => reject(new Error('è«‹æ±‚è¶…æ™‚')), 8000) // 8ç§’è¶…æ™‚
    );
    
    const requestPromise = fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${config.public.openaiApiKey}`
      },
      body: JSON.stringify(apiConfig)
    });
    
    onProgress?.('æ­£åœ¨ç­‰å¾…AIéŸ¿æ‡‰...', 50);
    
    const response = await Promise.race([requestPromise, timeoutPromise]);
    
    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      throw new Error(`APIè«‹æ±‚å¤±æ•—: ${response.status} - ${errorData.error?.message || response.statusText}`);
    }
    
    onProgress?.('æ­£åœ¨è™•ç†éŸ¿æ‡‰...', 80);
    const data = await response.json();
    
    if (!data.choices || !data.choices[0]?.message?.content) {
      throw new Error('APIå›æ‡‰æ ¼å¼ç•°å¸¸');
    }
    
    return parseAndValidateResult(data.choices[0].message.content, input);
  };

  /**
   * ğŸ” å˜—è©¦è§£æéƒ¨åˆ†çµæœï¼ˆç”¨æ–¼æµå¼éŸ¿æ‡‰ï¼‰
   */
  const tryParsePartialResult = (content: string): Partial<LLMClassifierResult> | null => {
    try {
      const jsonMatch = content.match(/\{[\s\S]*\}/);
      if (!jsonMatch) return null;
      
      const parsed = JSON.parse(jsonMatch[0]);
      
      // åªè¿”å›å·²ç¢ºå®šçš„éƒ¨åˆ†
      const partial: Partial<LLMClassifierResult> = {};
      
      if (parsed.type && ['expense', 'income'].includes(parsed.type)) {
        partial.type = parsed.type;
      }
      
      if (parsed.categoryId && typeof parsed.categoryId === 'string') {
        partial.categoryId = parsed.categoryId;
      }
      
      if (typeof parsed.confidence === 'number') {
        partial.confidence = Math.round(parsed.confidence);
      }
      
      return Object.keys(partial).length > 0 ? partial : null;
    } catch {
      return null;
    }
  };
  
  /**
   * Input preprocessing for better classification
   */
  const preprocessInput = (input: string): string => {
    return input
      .trim()
      .replace(/\s+/g, ' ') // Normalize whitespace
      .replace(/[^\u4e00-\u9fa5a-zA-Z0-9\s\-$ï¿¥Â¥.,]/g, '') // Remove special chars except currency
      .substring(0, 200); // Limit length
  };
  
  /**
   * Enhanced JSON parsing with comprehensive validation
   */
  const parseAndValidateResult = (content: string, originalInput: string): LLMClassifierResult => {
    try {
      // Extract JSON from response
      const jsonMatch = content.match(/\{[\s\S]*\}/);
      if (!jsonMatch) {
        throw new Error('å›æ‡‰ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆJSON');
      }
      
      const parsed = JSON.parse(jsonMatch[0]);
      
      // Comprehensive validation
      const validationErrors: string[] = [];
      
      if (!parsed.type || !['expense', 'income'].includes(parsed.type)) {
        validationErrors.push('äº¤æ˜“é¡å‹ç„¡æ•ˆ');
      }
      
      const validCategories = store.categories.filter(c => c.type === parsed.type);
      if (!parsed.categoryId || !validCategories.some(c => c.id === parsed.categoryId)) {
        validationErrors.push('é¡åˆ¥IDç„¡æ•ˆ');
      }
      
      if (typeof parsed.confidence !== 'number' || parsed.confidence < 0 || parsed.confidence > 100) {
        validationErrors.push('ä¿¡å¿ƒåº¦æ•¸å€¼ç„¡æ•ˆ');
      }
      
      if (!parsed.description || typeof parsed.description !== 'string') {
        validationErrors.push('æè¿°æ ¼å¼ç„¡æ•ˆ');
      }
      
      if (validationErrors.length > 0) {
        throw new Error(`æ•¸æ“šé©—è­‰å¤±æ•—: ${validationErrors.join(', ')}`);
      }
      
      // Return validated result
      return {
        type: parsed.type,
        categoryId: parsed.categoryId,
        confidence: Math.round(parsed.confidence),
        description: parsed.description.trim(),
        explanation: parsed.explanation || 'ç”±AIæ™ºèƒ½åˆ†æå®Œæˆ'
      };
      
    } catch (error: any) {
      console.error('JSONè§£æå¤±æ•—:', error.message, 'Content:', content);
      throw new Error(`çµæœè§£æå¤±æ•—: ${error.message}`);
    }
  };
  
  /**
   * Determine if an error is retryable
   */
  const isRetryableError = (error: any): boolean => {
    const retryableErrors = [
      'fetch', 'network', 'timeout', '429', '500', '502', '503', '504'
    ];
    
    const errorMessage = error?.message?.toLowerCase() || '';
    return retryableErrors.some(keyword => errorMessage.includes(keyword));
  };
  
  /**
   * Smart fallback classification with keyword-based category detection
   */
  const createFallbackResult = (description: string, errorContext?: string): LLMClassifierResult => {
    const lowerDesc = description.toLowerCase();
    
    // Smart category detection based on keywords
    let bestMatch = { category: store.categories.find(c => c.type === 'expense'), confidence: 25 };
    
    // Income keywords
    const incomeKeywords = ['è–ª', 'è–ªæ°´', 'è–ªè³‡', 'æ”¶å…¥', 'å…¥å¸³', 'çé‡‘', 'ç´…åˆ©', 'è‚¡æ¯', 'æŠ•è³‡', 'æ”¶åˆ°'];
    if (incomeKeywords.some(keyword => lowerDesc.includes(keyword))) {
      bestMatch = {
        category: store.categories.find(c => c.type === 'income') || 
                 store.categories.find(c => c.id === 'salary'),
        confidence: 60
      };
    }
    
    // Expense category keywords
    const categoryKeywords = {
      food: ['åƒ', 'å–', 'é¤', 'é£Ÿ', 'å’–å•¡', 'èŒ¶', 'éº¥ç•¶å‹', 'æ˜Ÿå·´å…‹', 'ä¾¿ç•¶', 'å°åƒ'],
      transport: ['äº¤é€š', 'è»Š', 'å…¬è»Š', 'æ·é‹', 'è¨ˆç¨‹è»Š', 'æ²¹', 'åœè»Š', 'uber'],
      shopping: ['è²·', 'è³¼', 'è¡£', 'é‹', 'åŒ…', 'åŒ–å¦', 'ç¶²è³¼', 'è¦çš®', 'æ·˜å¯¶'],
      entertainment: ['é›»å½±', 'éŠæˆ²', 'ktv', 'æ—…éŠ', 'å¨›æ¨‚', 'éŸ³æ¨‚', 'æ›¸'],
      healthcare: ['é†«', 'è—¥', 'å¥åº·', 'çœ‹ç—…', 'ç‰™é†«', 'çœ¼ç§‘', 'è¨ºæ‰€'],
      utilities: ['æ°´', 'é›»', 'ç“¦æ–¯', 'ç¶²è·¯', 'é›»è©±', 'æˆ¿ç§Ÿ', 'ç§Ÿé‡‘']
    };
    
    // Find best matching expense category
    for (const [categoryId, keywords] of Object.entries(categoryKeywords)) {
      if (keywords.some(keyword => lowerDesc.includes(keyword))) {
        const category = store.categories.find(c => c.id === categoryId);
        if (category) {
          bestMatch = { category, confidence: 70 };
          break;
        }
      }
    }
    
    // Final fallback
    const finalCategory = bestMatch.category || 
                         store.categories.find(c => c.type === 'expense') || 
                         store.categories[0] || 
                         { id: 'other', type: 'expense', name: 'å…¶ä»–' };
    
    return {
      type: finalCategory.type as 'expense' | 'income',
      categoryId: finalCategory.id,
      confidence: bestMatch.confidence,
      description: description || 'æœªçŸ¥äº¤æ˜“',
      explanation: `AIåˆ†æå¤±æ•—ï¼Œä½¿ç”¨é—œéµå­—åŒ¹é…: ${errorContext || 'è‡ªå‹•åˆ†é¡'}`,
      errorMessage: errorContext
    };
  };
  
  return {
    // ğŸš€ ä¸»è¦åˆ†é¡æ–¹æ³•
    classifyWithLLM,
    
    // âš¡ å¿«é€Ÿåˆ†é¡ï¼ˆç„¡æµå¼éŸ¿æ‡‰ï¼Œæœ€å¿«é€Ÿåº¦ï¼‰
    classifyFast: async (description: string): Promise<LLMClassifierResult> => {
      return classifyWithLLM(description, { enableStreaming: false });
    },
    
    // ğŸŒŠ æµå¼åˆ†é¡ï¼ˆæ›´å¥½çš„ç”¨æˆ¶é«”é©—ï¼‰
    classifyStreaming: async (
      description: string, 
      callbacks: {
        onProgress: (stage: string, progress: number) => void;
        onIntermediateResult: (result: Partial<LLMClassifierResult>) => void;
      }
    ): Promise<LLMClassifierResult> => {
      return classifyWithLLM(description, {
        enableStreaming: true,
        onProgress: callbacks.onProgress,
        onIntermediateResult: callbacks.onIntermediateResult
      });
    },
    
    // ğŸ¯ æ™ºèƒ½åˆ†é¡ï¼ˆè‡ªå‹•é¸æ“‡æœ€ä½³æ–¹æ³•ï¼‰
    classifyIntelligent: async (
      description: string,
      options?: {
        preferSpeed?: boolean; // å„ªå…ˆé€Ÿåº¦é‚„æ˜¯é«”é©—
        onProgress?: (stage: string, progress: number) => void;
        onIntermediateResult?: (result: Partial<LLMClassifierResult>) => void;
      }
    ): Promise<LLMClassifierResult> => {
      const { preferSpeed = false } = options || {};
      
      // çŸ­æè¿°ä½¿ç”¨å¿«é€Ÿæ¨¡å¼ï¼Œé•·æè¿°ä½¿ç”¨æµå¼æ¨¡å¼
      const useStreaming = !preferSpeed && description.length > 20;
      
      return classifyWithLLM(description, {
        enableStreaming: useStreaming,
        onProgress: options?.onProgress,
        onIntermediateResult: options?.onIntermediateResult
      });
    },
    
    // Export for testing purposes
    buildClassificationPrompt,
    
    // æ‰¹é‡åˆ†é¡ï¼ˆé€²éšåŠŸèƒ½ï¼‰
    classifyBatch: async (descriptions: string[], options?: ClassificationOptions): Promise<LLMClassifierResult[]> => {
      const results: LLMClassifierResult[] = [];
      const startTime = Date.now();
      
      // ä¸¦è¡Œè™•ç†å°æ‰¹é‡ï¼Œé¿å… API é™åˆ¶
      const batchSize = 3;
      for (let i = 0; i < descriptions.length; i += batchSize) {
        const batch = descriptions.slice(i, i + batchSize);
        
        const batchPromises = batch.map(desc => 
          classifyWithLLM(desc, { enableStreaming: false })
        );
        
        const batchResults = await Promise.all(batchPromises);
        results.push(...batchResults);
        
        // æ‰¹æ¬¡é–“å»¶é²
        if (i + batchSize < descriptions.length) {
          await new Promise(resolve => setTimeout(resolve, 500));
        }
      }
      
      console.log(`âœ… Batch classification completed: ${descriptions.length} items in ${Date.now() - startTime}ms`);
      return results;
    },
    
    // ä¸¦è¡Œåˆ†é¡ï¼ˆæœ€å¿«ä½†æ¶ˆè€—æ›´å¤š API é…é¡ï¼‰
    classifyParallel: async (descriptions: string[], maxConcurrent = 5): Promise<LLMClassifierResult[]> => {
      const results: LLMClassifierResult[] = [];
      
      for (let i = 0; i < descriptions.length; i += maxConcurrent) {
        const batch = descriptions.slice(i, i + maxConcurrent);
        const batchPromises = batch.map(desc => classifyWithLLM(desc));
        const batchResults = await Promise.all(batchPromises);
        results.push(...batchResults);
      }
      
      return results;
    },
    
    // ç²å–åˆ†é¡çµ±è¨ˆ
    getClassificationStats: () => {
      const categories = store.categories;
      return {
        totalCategories: categories.length,
        expenseCategories: categories.filter(c => c.type === 'expense').length,
        incomeCategories: categories.filter(c => c.type === 'income').length,
        availableCategories: categories.map(c => ({ id: c.id, name: c.name, type: c.type }))
      };
    },
    
    // é©—è­‰è¼¸å…¥
    validateInput: (input: string): { isValid: boolean; issues: string[] } => {
      const issues: string[] = [];
      
      if (!input || !input.trim()) {
        issues.push('è¼¸å…¥ç‚ºç©º');
      }
      
      if (input.length > 200) {
        issues.push('è¼¸å…¥éé•·ï¼ˆè¶…é200å­—ç¬¦ï¼‰');
      }
      
      if (!/[\u4e00-\u9fa5]/.test(input) && !/[a-zA-Z]/.test(input)) {
        issues.push('ç¼ºå°‘æœ‰æ•ˆçš„æ–‡å­—å…§å®¹');
      }
      
      return {
        isValid: issues.length === 0,
        issues
      };
    },
    
    // ğŸ”§ å·¥å…·æ–¹æ³•
    utils: {
      preprocessInput,
      createFallbackResult,
      tryParsePartialResult
    }
  };
}